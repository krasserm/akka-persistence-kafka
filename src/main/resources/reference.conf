akka {
  actor {
    serializers {
      kafka-event = "akka.persistence.kafka.journal.KafkaEventSerializer"
      kafka-snapshot = "akka.persistence.kafka.snapshot.KafkaSnapshotSerializer"
    }

    serialization-bindings {
      "akka.persistence.kafka.Event" = kafka-event
      "akka.persistence.kafka.snapshot.KafkaSnapshot" = kafka-snapshot
    }
  }
}

kafka-journal {

  # FQCN of the Kafka journal plugin
  class = "akka.persistence.kafka.journal.KafkaJournal"

  # Dispatcher for the plugin actor
  plugin-dispatcher = "kafka-journal.default-dispatcher"

  # Number of concurrent writers (should be <= number of available threads in
  # dispatcher).
  write-concurrency = 8

  # Time in milliseconds to wait for a writer to complete a batch
  writer-timeout-ms = 5000

  # The partition to use when publishing to and consuming from journal topics.
  partition = 0

  # Default dispatcher for plugin actor.
  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 8
    }
  }

  consumer {
    # -------------------------------------------------------------------
    # Simple consumer configuration (used for message replay and reading
    # metadata).
    #
    # See http://kafka.apache.org/documentation.html#consumerconfigs
    # See http://kafka.apache.org/documentation.html#simpleconsumerapi
    # -------------------------------------------------------------------

    poll-timeout = 3000
  }

  producer {
    # -------------------------------------------------------------------
    # PersistentRepr producer (to journal topics) configuration.
    #
    # See http://kafka.apache.org/documentation.html#producerconfigs
    #
    # -------------------------------------------------------------------

    acks = -1

    # Increase if hundreds of topics are created during initialization.
    retries = 5

    # Increase if hundreds of topics are created during initialization.
    retry.backoff.ms = 100

    # Add further Kafka producer settings here, if needed.
    # ...
  }

  event.producer {
    # -------------------------------------------------------------------
    # Event producer (to user-defined topics) configuration.
    #
    # See http://kafka.apache.org/documentation.html#producerconfigs
    # -------------------------------------------------------------------

    acks = -1

    topic.mapper.class = "akka.persistence.kafka.DefaultEventTopicMapper"


    # Add further Kafka producer settings here, if needed.
    # ...
  }

}

kafka-snapshot-store {

  # FQCN of the Kafka snapshot store plugin
  class = "akka.persistence.kafka.snapshot.KafkaSnapshotStore"

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "kafka-snapshot-store.default-dispatcher"

  # The partition to use when publishing to and consuming from snapshot topics.
  partition = 0

  # Topic name prefix (which prepended to persistenceId)
  prefix = "snapshot-"

  # If set to true snapshots with sequence numbers higher than the sequence number
  # of the latest entry in their corresponding journal topic are ignored. This is
  # necessary to recover from certain Kafka failure scenarios. Should only be set
  # to false for isolated snapshot store tests.
  ignore-orphan = true

  # Default dispatcher for plugin actor.
  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 8
    }
  }

  consumer {
    # -------------------------------------------------------------------
    # New consumer configuration (used for loading snapshots and
    # reading metadata).
    #
    # See http://kafka.apache.org/documentation.html#consumerconfigs
    # See http://kafka.apache.org/documentation.html#consumerapi
    # -------------------------------------------------------------------

    poll-timeout = 3000
  }

  producer {
    # -------------------------------------------------------------------
    # Snapshot producer configuration.
    #
    # See http://kafka.apache.org/documentation.html#producerconfigs
    #
    # -------------------------------------------------------------------

    acks = -1

    # Increase if hundreds of topics are created during initialization.
    retries = 5

    # Increase if hundreds of topics are created during initialization.
    retry.backoff.ms = 500

    # Add further Kafka producer settings here, if needed.
    # ...
  }

}
